#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ–‡æ¡£å®ˆå«å·¥å…· (Doc Guard)

åŠŸèƒ½ï¼š
- è‡ªåŠ¨æ£€æµ‹æ–‡æ¡£å¤§å°
- æ™ºèƒ½é€‰æ‹©åŠ è½½ç­–ç•¥
- æ‹¦æˆªå¤§æ–‡æ¡£ç›´æ¥è¯»å–
- Token é¢„ç®—ç®¡ç†

ä½¿ç”¨ç¤ºä¾‹ï¼š
    # åŸºç¡€ç”¨æ³•
    python scripts/doc_guard.py --docs "PLANNING.md,TASK.md"

    # æŒ‡å®šç« èŠ‚
    python scripts/doc_guard.py \
      --docs "docs/guides/large_guide.md" \
      --sections '{"docs/guides/large_guide.md": ["Step 3", "MCP Integration"]}'

    # è‡ªå®šä¹‰ token é¢„ç®—
    python scripts/doc_guard.py --docs "PLANNING.md" --budget 5000
"""

import sys
import json
import argparse
from pathlib import Path
from typing import List, Dict, Optional

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

try:
    from commands.lib.doc_loader import DocLoader
except ImportError:
    print("âš ï¸ è­¦å‘Š: æ— æ³•å¯¼å…¥ DocLoaderï¼Œä½¿ç”¨ç®€åŒ–æ¨¡å¼", file=sys.stderr)
    DocLoader = None


class DocGuardError(Exception):
    """æ–‡æ¡£å®ˆå«é”™è¯¯"""
    pass


class DocGuard:
    """æ–‡æ¡£å®ˆå«æ ¸å¿ƒç±»"""

    # æ–‡æ¡£å¤§å°é˜ˆå€¼ï¼ˆè¡Œæ•°ï¼‰
    SIZE_SMALL = 100      # < 100: å®Œæ•´è¯»å–
    SIZE_MEDIUM = 300     # 100-300: æ‘˜è¦æ¨¡å¼
    SIZE_LARGE = 800      # 300-800: ç« èŠ‚æ¨¡å¼
    # > 800: æ‹’ç»å®Œæ•´è¯»å–

    def __init__(self, token_budget: int = 20000):
        """
        åˆå§‹åŒ–æ–‡æ¡£å®ˆå«

        Args:
            token_budget: Token é¢„ç®—ä¸Šé™
        """
        self.loader = DocLoader() if DocLoader else None
        self.token_budget = token_budget
        self.token_used = 0
        self.violations = []
        self.load_stats = []

    def load_docs(
        self,
        doc_paths: List[str],
        sections_map: Optional[Dict[str, List[str]]] = None
    ) -> Dict[str, str]:
        """
        æ‰¹é‡åŠ è½½æ–‡æ¡£

        Args:
            doc_paths: æ–‡æ¡£è·¯å¾„åˆ—è¡¨
            sections_map: {doc_path: [sections]} ç« èŠ‚æ˜ å°„ï¼ˆå¯é€‰ï¼‰

        Returns:
            {doc_path: content} æ–‡æ¡£å†…å®¹å­—å…¸
        """
        results = {}
        sections_map = sections_map or {}

        print(f"\nğŸ“š Doc Guard å¼€å§‹åŠ è½½ {len(doc_paths)} ä¸ªæ–‡æ¡£...\n", file=sys.stderr)

        for doc_path in doc_paths:
            sections = sections_map.get(doc_path)
            try:
                content = self._load_single(doc_path, sections)
                results[doc_path] = content
            except DocGuardError as e:
                self.violations.append(str(e))
                print(f"âŒ {e}\n", file=sys.stderr)

        # è¾“å‡ºç»Ÿè®¡
        self._print_summary()

        return results

    def _load_single(self, doc_path: str, sections: Optional[List[str]] = None) -> str:
        """
        å•ä¸ªæ–‡æ¡£æ™ºèƒ½åŠ è½½

        Args:
            doc_path: æ–‡æ¡£è·¯å¾„
            sections: éœ€è¦åŠ è½½çš„ç« èŠ‚åˆ—è¡¨

        Returns:
            æ–‡æ¡£å†…å®¹

        Raises:
            DocGuardError: æ–‡æ¡£ä¸å­˜åœ¨æˆ–è¶…è¿‡å¤§å°é™åˆ¶
        """
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        path = Path(doc_path)
        if not path.exists():
            raise DocGuardError(f"æ–‡æ¡£ä¸å­˜åœ¨: {doc_path}")

        # ç»Ÿè®¡è¡Œæ•°
        lines = self._count_lines(doc_path)

        print(f"ğŸ“„ {doc_path}: {lines} è¡Œ", file=sys.stderr)

        # ç­–ç•¥é€‰æ‹©
        if lines < self.SIZE_SMALL:
            strategy = "å®Œæ•´è¯»å–"
            content = self._read_full(doc_path)
            tokens = self._estimate_tokens(content)

        elif lines < self.SIZE_MEDIUM:
            strategy = "æ‘˜è¦æ¨¡å¼ï¼ˆ50è¡Œï¼‰"
            if self.loader:
                content = self.loader.load_summary(doc_path, max_lines=50)
            else:
                # é™çº§ï¼šè¯»å–å‰50è¡Œ
                content = self._read_head(doc_path, 50)
            tokens = self._estimate_tokens(content)

        elif lines < self.SIZE_LARGE:
            if not sections:
                raise DocGuardError(
                    f"æ–‡æ¡£ {doc_path} æœ‰ {lines} è¡Œï¼Œå¿…é¡»æŒ‡å®š --sections å‚æ•°\n"
                    f"  å»ºè®®: ä½¿ç”¨ --sections '{{\"{doc_path}\": [\"ç« èŠ‚1\", \"ç« èŠ‚2\"]}}'"
                )
            strategy = f"ç« èŠ‚æ¨¡å¼ {sections}"
            if self.loader:
                section_dict = self.loader.load_sections(doc_path, sections)
                # åˆå¹¶æ‰€æœ‰ç« èŠ‚å†…å®¹
                content = "\n\n".join(section_dict.values())
            else:
                # é™çº§ï¼šè¯»å–å‰100è¡Œå¹¶æç¤º
                content = self._read_head(doc_path, 100)
                content = f"[é™çº§æ¨¡å¼: ä»…åŠ è½½å‰100è¡Œ]\n\n{content}"
            tokens = self._estimate_tokens(content)

        else:
            raise DocGuardError(
                f"æ–‡æ¡£ {doc_path} æœ‰ {lines} è¡Œï¼Œè¶…è¿‡é™åˆ¶ï¼ˆ{self.SIZE_LARGE}è¡Œï¼‰\n"
                f"  å»ºè®®: å¿…é¡»æŒ‡å®š --sections åŠ è½½éƒ¨åˆ†ç« èŠ‚"
            )

        # æ›´æ–°ç»Ÿè®¡
        self.token_used += tokens
        self.load_stats.append({
            'path': doc_path,
            'lines': lines,
            'strategy': strategy,
            'tokens': tokens
        })

        print(f"  âœ… ç­–ç•¥: {strategy}", file=sys.stderr)
        print(f"  ğŸ“Š Token: ~{tokens}", file=sys.stderr)

        # æ£€æŸ¥é¢„ç®—
        if self.token_used > self.token_budget:
            print(
                f"  âš ï¸  è­¦å‘Š: Token æ¶ˆè€— {self.token_used} è¶…å‡ºé¢„ç®— {self.token_budget}",
                file=sys.stderr
            )

        return content

    def _count_lines(self, doc_path: str) -> int:
        """ç»Ÿè®¡æ–‡æ¡£è¡Œæ•°"""
        try:
            with open(doc_path, 'r', encoding='utf-8') as f:
                return len(f.readlines())
        except Exception as e:
            raise DocGuardError(f"æ— æ³•è¯»å–æ–‡æ¡£ {doc_path}: {e}")

    def _read_full(self, doc_path: str) -> str:
        """å®Œæ•´è¯»å–å°æ–‡æ¡£"""
        try:
            with open(doc_path, 'r', encoding='utf-8') as f:
                return f.read()
        except Exception as e:
            raise DocGuardError(f"æ— æ³•è¯»å–æ–‡æ¡£ {doc_path}: {e}")

    def _read_head(self, doc_path: str, n_lines: int) -> str:
        """è¯»å–æ–‡æ¡£å‰ N è¡Œ"""
        try:
            with open(doc_path, 'r', encoding='utf-8') as f:
                lines = [next(f) for _ in range(n_lines)]
                return ''.join(lines)
        except StopIteration:
            # æ–‡ä»¶ä¸è¶³ N è¡Œï¼Œè¿”å›å…¨éƒ¨
            with open(doc_path, 'r', encoding='utf-8') as f:
                return f.read()
        except Exception as e:
            raise DocGuardError(f"æ— æ³•è¯»å–æ–‡æ¡£ {doc_path}: {e}")

    def _estimate_tokens(self, text: str) -> int:
        """ä¼°ç®—æ–‡æœ¬çš„ token æ•°é‡ï¼ˆç²—ç•¥ä¼°è®¡ï¼š1 token â‰ˆ 4 å­—ç¬¦ï¼‰"""
        return len(text) // 4

    def _print_summary(self):
        """è¾“å‡ºåŠ è½½ç»Ÿè®¡æ‘˜è¦"""
        print(f"\n{'='*80}", file=sys.stderr)
        print(f"ğŸ“Š Doc Guard åŠ è½½ç»Ÿè®¡", file=sys.stderr)
        print(f"{'='*80}", file=sys.stderr)

        print(f"\næ–‡æ¡£åŠ è½½è¯¦æƒ…:", file=sys.stderr)
        for stat in self.load_stats:
            print(f"  â€¢ {stat['path']}", file=sys.stderr)
            print(f"    - è¡Œæ•°: {stat['lines']}", file=sys.stderr)
            print(f"    - ç­–ç•¥: {stat['strategy']}", file=sys.stderr)
            print(f"    - Token: ~{stat['tokens']}", file=sys.stderr)

        print(f"\næ€»è®¡:", file=sys.stderr)
        print(f"  â€¢ åŠ è½½æ–‡æ¡£æ•°: {len(self.load_stats)}", file=sys.stderr)
        print(f"  â€¢ Token æ¶ˆè€—: ~{self.token_used}", file=sys.stderr)
        print(f"  â€¢ Token é¢„ç®—: {self.token_budget}", file=sys.stderr)
        print(f"  â€¢ é¢„ç®—ä½¿ç”¨ç‡: {self.token_used / self.token_budget * 100:.1f}%", file=sys.stderr)

        if self.violations:
            print(f"\nâš ï¸  è¿è§„è®°å½•:", file=sys.stderr)
            for v in self.violations:
                print(f"  â€¢ {v}", file=sys.stderr)
        else:
            print(f"\nâœ… æ— è¿è§„è®°å½•", file=sys.stderr)

        print(f"\n{'='*80}\n", file=sys.stderr)


def main():
    """å‘½ä»¤è¡Œæ¥å£"""
    parser = argparse.ArgumentParser(
        description="æ–‡æ¡£å®ˆå«å·¥å…· - é˜²æ­¢å¤§æ–‡æ¡£è¯»å–å¯¼è‡´ä¸Šä¸‹æ–‡çˆ†ç‚¸",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  # åŸºç¡€ç”¨æ³•
  python scripts/doc_guard.py --docs "PLANNING.md,TASK.md"

  # æŒ‡å®šç« èŠ‚
  python scripts/doc_guard.py \\
    --docs "docs/guides/large_guide.md" \\
    --sections '{"docs/guides/large_guide.md": ["Step 3", "MCP Integration"]}'

  # è‡ªå®šä¹‰ token é¢„ç®—
  python scripts/doc_guard.py --docs "PLANNING.md" --budget 5000
        """
    )

    parser.add_argument(
        '--docs',
        required=True,
        help='æ–‡æ¡£è·¯å¾„ï¼Œé€—å·åˆ†éš”ï¼ˆå¦‚: PLANNING.md,TASK.mdï¼‰'
    )
    parser.add_argument(
        '--sections',
        help='ç« èŠ‚æ˜ å°„ï¼ˆJSON æ ¼å¼ï¼‰ï¼Œå¦‚: \'{"path/to/doc.md": ["ç« èŠ‚1", "ç« èŠ‚2"]}\''
    )
    parser.add_argument(
        '--budget',
        type=int,
        default=20000,
        help='Token é¢„ç®—ä¸Šé™ï¼ˆé»˜è®¤: 20000ï¼‰'
    )
    parser.add_argument(
        '--quiet',
        action='store_true',
        help='å®‰é™æ¨¡å¼ï¼Œä»…è¾“å‡ºæ–‡æ¡£å†…å®¹'
    )

    args = parser.parse_args()

    # è§£ææ–‡æ¡£åˆ—è¡¨
    doc_paths = [d.strip() for d in args.docs.split(',')]

    # è§£æç« èŠ‚æ˜ å°„
    sections_map = None
    if args.sections:
        try:
            sections_map = json.loads(args.sections)
        except json.JSONDecodeError as e:
            print(f"âŒ é”™è¯¯: æ— æ³•è§£æ --sections å‚æ•°: {e}", file=sys.stderr)
            sys.exit(1)

    # åˆ›å»ºå®ˆå«å¹¶åŠ è½½æ–‡æ¡£
    guard = DocGuard(token_budget=args.budget)

    try:
        results = guard.load_docs(doc_paths, sections_map)
    except Exception as e:
        print(f"âŒ åŠ è½½å¤±è´¥: {e}", file=sys.stderr)
        sys.exit(1)

    # è¾“å‡ºæ–‡æ¡£å†…å®¹
    if not args.quiet:
        print("\n" + "="*80)
        print("ğŸ“„ æ–‡æ¡£å†…å®¹")
        print("="*80 + "\n")

    for doc_path, content in results.items():
        if not args.quiet:
            print(f"# {doc_path}\n")
        print(content)
        if not args.quiet:
            print("\n" + "-"*80 + "\n")

    # æ£€æŸ¥è¿è§„
    if guard.violations:
        print(f"\nâš ï¸  å‘ç° {len(guard.violations)} ä¸ªè¿è§„", file=sys.stderr)
        sys.exit(1)

    sys.exit(0)


if __name__ == '__main__':
    main()
