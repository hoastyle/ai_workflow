---
title: "DocLoader é›†æˆç¤ºä¾‹"
description: "å¦‚ä½•åœ¨ workflow å‘½ä»¤ä¸­é›†æˆ DocLoader"
type: "æ•™ç¨‹"
status: "å®Œæˆ"
priority: "é«˜"
created_date: "2025-12-09"
last_updated: "2025-12-09"
related_documents:
  - "docs/examples/doc_loader_usage.md"
  - "commands/lib/doc_loader.py"
related_code:
  - "commands/wf_03_prime.md"
  - "commands/wf_08_review.md"
tags: ["integration", "doc-loader", "workflow"]
authors: ["Claude"]
version: "1.0"
---

# DocLoader Workflow é›†æˆç¤ºä¾‹

## é›†æˆæ–¹æ¡ˆæ¦‚è§ˆ

æœ¬æ–‡æ¡£å±•ç¤ºå¦‚ä½•åœ¨ä¸‰ä¸ªé«˜é¢‘å‘½ä»¤ä¸­é›†æˆ DocLoaderï¼Œå®ç°æ¸è¿›å¼ä¼˜åŒ–ï¼š

| å‘½ä»¤ | å½“å‰è¡Œæ•° | ä¼˜åŒ–ç›®æ ‡ | TokenèŠ‚çœ | ä¼˜å…ˆçº§ |
|------|---------|---------|----------|--------|
| **wf_03_prime** | 1092 | ~500 | 2k-3k | ğŸ”´ æœ€é«˜ |
| **wf_08_review** | 1764 | ~800 | 3k-5k | ğŸ”´ æœ€é«˜ |
| **wf_05_code** | 1158 | ~600 | 2k-4k | ğŸŸ¡ é«˜ |

**æ€»ä¼˜åŒ–æ½œåŠ›**: 7k-12k tokens èŠ‚çœ

---

## ç¤ºä¾‹ 1: wf_03_prime.md é›†æˆ

### å½“å‰é—®é¢˜

wf_03_prime.md (1092 è¡Œ) éœ€è¦åŠ è½½å¤šä¸ªæŠ€æœ¯æ–‡æ¡£ï¼š
- docs/guides/wf_03_prime_smart_loading.md
- docs/guides/wf_03_prime_workflows.md
- docs/guides/wf_03_prime_mcp_serena.md

**é—®é¢˜**: å…¨æ–‡åŠ è½½å¯¼è‡´ ~3k tokens æ¶ˆè€—

### ä¼˜åŒ–æ–¹æ¡ˆ

ä½¿ç”¨ DocLoader æŒ‰éœ€åŠ è½½ç›¸å…³ç« èŠ‚ï¼š

```markdown
## Step 1.2: æ™ºèƒ½æ–‡æ¡£åŠ è½½

æ ¹æ®ç”¨æˆ·çš„å·¥ä½œæ¨¡å¼ï¼ŒåªåŠ è½½ç›¸å…³æŒ‡å¯¼ï¼š

\`\`\`python
from commands.lib.doc_loader import DocLoader

loader = DocLoader()

# æ£€æµ‹ç”¨æˆ·å·¥ä½œæ¨¡å¼
if mode == "Quick Start":
    # å¿«é€Ÿå¯åŠ¨æ¨¡å¼ï¼šåªåŠ è½½æ‘˜è¦
    content = loader.load_summary("docs/guides/wf_03_prime_smart_loading.md")

elif mode == "Full Context":
    # å®Œæ•´ä¸Šä¸‹æ–‡æ¨¡å¼ï¼šåŠ è½½å…³é”®ç« èŠ‚
    sections = loader.load_sections(
        "docs/guides/wf_03_prime_smart_loading.md",
        sections=["Step 2: æ–‡æ¡£åˆ†å±‚åŠ è½½", "Step 3: Tokené¢„ç®—ç®¡ç†"]
    )

elif mode == "Task Focused":
    # ä»»åŠ¡èšç„¦æ¨¡å¼ï¼šæ ¹æ®å½“å‰ä»»åŠ¡é€‰æ‹©ç« èŠ‚
    if current_task == "å®ç°åŠŸèƒ½":
        sections = ["å¼€å‘å®ç°ç›¸å…³æ–‡æ¡£"]
    elif current_task == "è°ƒè¯•é—®é¢˜":
        sections = ["è°ƒè¯•å’Œæ•…éšœæ’æŸ¥"]

    content = loader.load_sections(
        "docs/guides/wf_03_prime_workflows.md",
        sections=sections
    )

# Token ä¼°ç®—å’Œé¢„ç®—æ§åˆ¶
estimated = loader.estimate_tokens(str(content))
print(f"ğŸ“Š å°†åŠ è½½ ~{estimated} tokens çš„æ–‡æ¡£")

if estimated > 2000:
    print("âš ï¸ æ–‡æ¡£è¾ƒå¤§ï¼Œè€ƒè™‘ä½¿ç”¨æ‘˜è¦æ¨¡å¼")
\`\`\`

**ä¼˜åŒ–æ•ˆæœ**:
- Quick Start: 3000 â†’ 300 tokens (90% èŠ‚çœ)
- Full Context: 3000 â†’ 800 tokens (73% èŠ‚çœ)
- Task Focused: 3000 â†’ 500 tokens (83% èŠ‚çœ)
```

---

## ç¤ºä¾‹ 2: wf_08_review.md é›†æˆ

### å½“å‰é—®é¢˜

wf_08_review.md (1764 è¡Œ) åŒ…å«å¤§é‡åµŒå…¥å¼æ–‡æ¡£ï¼š
- MCP ä½¿ç”¨æŒ‡å—
- ä»£ç å®¡æŸ¥è§„èŒƒ
- è®¾è®¡æ¨¡å¼å‚è€ƒ

**é—®é¢˜**: å†…å®¹å…¨éƒ¨åµŒå…¥å‘½ä»¤æ–‡ä»¶ï¼Œå¯¼è‡´æ–‡ä»¶è¿‡å¤§

### ä¼˜åŒ–æ–¹æ¡ˆ

å°†æ–‡æ¡£å¤–ç§»ï¼Œä½¿ç”¨ DocLoader æŒ‰éœ€åŠ è½½ï¼š

```markdown
## Dimension 3: è®¾è®¡ä¼˜é›…åº¦è¯„å®¡

ä½¿ç”¨ DocLoader åŠ è½½è®¾è®¡æ¨¡å¼å‚è€ƒï¼š

\`\`\`python
from commands.lib.doc_loader import DocLoader

loader = DocLoader()

# åªåœ¨éœ€è¦æ—¶åŠ è½½è®¾è®¡æ¨¡å¼å‚è€ƒ
if review_needs_design_patterns:
    patterns = loader.load_sections(
        "docs/reference/DESIGN_PATTERNS.md",
        sections=[
            "SOLID åŸåˆ™",
            "ä¾èµ–æ³¨å…¥",
            "ç­–ç•¥æ¨¡å¼"
        ]
    )

    # æ˜¾ç¤ºç›¸å…³æ¨¡å¼
    for pattern_name, content in patterns.items():
        print(f"### å‚è€ƒ: {pattern_name}")
        print(content[:500] + "...")  # æ˜¾ç¤ºå‰500å­—ç¬¦

# MCP ä½¿ç”¨æŒ‡å—ä¹ŸæŒ‰éœ€åŠ è½½
if code_uses_mcp:
    mcp_guide = loader.load_sections(
        "docs/integration/MCP_USAGE_GUIDE.md",
        sections=["Serena æœ€ä½³å®è·µ", "Context7 é›†æˆ"]
    )
\`\`\`

**ä¼˜åŒ–æ•ˆæœ**:
- å‘½ä»¤æ–‡ä»¶: 1764 â†’ ~800 è¡Œ (55% å‡å°‘)
- Token æ¶ˆè€—: ~5k â†’ ~1.5k (70% èŠ‚çœ)
- æ–‡æ¡£åˆ†ç¦»: å°†åµŒå…¥å†…å®¹ç§»åˆ°ç‹¬ç«‹æ–‡æ¡£
```

---

## ç¤ºä¾‹ 3: wf_05_code.md é›†æˆ

### å½“å‰é—®é¢˜

wf_05_code.md (1158 è¡Œ) åŒ…å«ï¼š
- å¼€å‘æµç¨‹æŒ‡å¯¼
- MCP é›†æˆæ–‡æ¡£
- åç»­å·¥ä½œæµå¯¼èˆª

**é—®é¢˜**: ç”¨æˆ·é€šå¸¸åªéœ€è¦å½“å‰æ­¥éª¤çš„æŒ‡å¯¼

### ä¼˜åŒ–æ–¹æ¡ˆ

æ¸è¿›å¼åŠ è½½ï¼Œåªæ˜¾ç¤ºå½“å‰æ­¥éª¤ï¼š

```markdown
## Step 3: æ¸è¿›å¼å¼€å‘

æ ¹æ®å¼€å‘æ¨¡å¼åŠ¨æ€åŠ è½½æ–‡æ¡£ï¼š

\`\`\`python
from commands.lib.doc_loader import DocLoader

loader = DocLoader()

# ç¬¬ä¸€æ¬¡ï¼šåªåŠ è½½å½“å‰æ­¥éª¤çš„æŒ‡å¯¼
current_step = get_current_step()  # e.g., "Step 3"

workflow_guide = loader.load_sections(
    "docs/guides/wf_05_code_workflows.md",
    sections=[f"{current_step}: æ¸è¿›å¼å¼€å‘"]
)

print(f"ğŸ“– å½“å‰æ­¥éª¤æŒ‡å¯¼:")
print(workflow_guide[f"{current_step}: æ¸è¿›å¼å¼€å‘"])

# å¦‚æœç”¨æˆ·éœ€è¦æ›´å¤šä¿¡æ¯ï¼Œå†åŠ è½½
if user_needs_more_context:
    additional = loader.load_sections(
        "docs/guides/wf_05_code_workflows.md",
        sections=["Step 4: è´¨é‡ä¿è¯", "Step 5: é›†æˆæµ‹è¯•"]
    )

# Token é¢„ç®—ç®¡ç†
cache_stats = loader.get_cache_stats()
print(f"ğŸ“Š ç¼“å­˜çŠ¶æ€: {cache_stats['items']} é¡¹, "
      f"~{cache_stats['estimated_tokens']} tokens")
\`\`\`

**ä¼˜åŒ–æ•ˆæœ**:
- åˆå§‹åŠ è½½: 3k â†’ 600 tokens (80% èŠ‚çœ)
- ç¼“å­˜å‘½ä¸­: 0 â†’ 90% (åç»­åŠ è½½é€Ÿåº¦æå‡)
- ç”¨æˆ·ä½“éªŒ: æ¸è¿›å¼å¼•å¯¼ï¼Œé¿å…ä¿¡æ¯è¿‡è½½
```

---

## å®æ–½è·¯çº¿å›¾

### é˜¶æ®µ 1: åŸºç¡€é›†æˆ (1-2 å¤©)

**ç›®æ ‡**: åœ¨ wf_03_prime.md ä¸­é›†æˆ DocLoader

**æ­¥éª¤**:
1. è¯†åˆ«éœ€è¦å¤–ç§»çš„å¤§æ–‡æ¡£
2. é‡æ„åŠ è½½é€»è¾‘ä½¿ç”¨ DocLoader
3. æµ‹è¯• 3 ç§å·¥ä½œæ¨¡å¼
4. æ”¶é›† token æ¶ˆè€—æ•°æ®

**é¢„æœŸæˆæœ**:
- wf_03_prime.md: 1092 â†’ ~500 è¡Œ
- Token èŠ‚çœ: 2k-3k per execution

### é˜¶æ®µ 2: æ‰©å±•é›†æˆ (2-3 å¤©)

**ç›®æ ‡**: é›†æˆåˆ° wf_08_review.md å’Œ wf_05_code.md

**æ­¥éª¤**:
1. å°†åµŒå…¥æ–‡æ¡£ç§»åˆ°ç‹¬ç«‹æ–‡ä»¶
2. æ›´æ–°å‘½ä»¤ä½¿ç”¨ DocLoader
3. åˆ›å»ºæ–‡æ¡£ç´¢å¼•å’Œå¯¼èˆª
4. éªŒè¯åŠŸèƒ½å®Œæ•´æ€§

**é¢„æœŸæˆæœ**:
- wf_08_review.md: 1764 â†’ ~800 è¡Œ
- wf_05_code.md: 1158 â†’ ~600 è¡Œ
- æ€» token èŠ‚çœ: 7k-12k

### é˜¶æ®µ 3: å…¨é¢ä¼˜åŒ– (1 å‘¨)

**ç›®æ ‡**: ä¼˜åŒ–æ‰€æœ‰ workflow å‘½ä»¤

**æ­¥éª¤**:
1. åˆ†æå…¶ä½™ 13 ä¸ªå‘½ä»¤
2. è¯†åˆ«ä¼˜åŒ–æœºä¼š
3. æ‰¹é‡é›†æˆ DocLoader
4. å»ºç«‹æœ€ä½³å®è·µæ–‡æ¡£

**é¢„æœŸæˆæœ**:
- é¡¹ç›®æ€»è¡Œæ•°: 10,027 â†’ ~5,000 è¡Œ (50% å‡å°‘)
- å¹³å‡ token æ¶ˆè€—: å‡å°‘ 60-70%

---

## é›†æˆæ£€æŸ¥æ¸…å•

åœ¨é›†æˆ DocLoader åˆ°æ¯ä¸ªå‘½ä»¤æ—¶ï¼Œç¡®ä¿ï¼š

### åŠŸèƒ½å®Œæ•´æ€§
- [ ] æ‰€æœ‰åŸæœ‰åŠŸèƒ½æ­£å¸¸å·¥ä½œ
- [ ] æ–‡æ¡£å†…å®¹å®Œæ•´æ— é—æ¼
- [ ] ç« èŠ‚å¼•ç”¨æ­£ç¡®æ— è¯¯
- [ ] é”™è¯¯å¤„ç†å¥å£®

### æ€§èƒ½ä¼˜åŒ–
- [ ] Token æ¶ˆè€—é™ä½ > 50%
- [ ] åŠ è½½é€Ÿåº¦æ— æ˜æ˜¾å»¶è¿Ÿ
- [ ] ç¼“å­˜å‘½ä¸­ç‡ > 80%
- [ ] å†…å­˜å ç”¨åˆç†

### ç”¨æˆ·ä½“éªŒ
- [ ] æ¸è¿›å¼åŠ è½½é€»è¾‘æ¸…æ™°
- [ ] æ–‡æ¡£å¯¼èˆªä¾¿æ·
- [ ] é”™è¯¯æç¤ºå‹å¥½
- [ ] è°ƒè¯•ä¿¡æ¯å……è¶³

### æ–‡æ¡£ç»´æŠ¤
- [ ] å¤–ç§»æ–‡æ¡£æœ‰å®Œæ•´ Frontmatter
- [ ] ç´¢å¼•æ›´æ–°åœ¨ KNOWLEDGE.md
- [ ] ä½¿ç”¨ç¤ºä¾‹æ¸…æ™°
- [ ] ç›¸å…³æ€§é“¾æ¥æ­£ç¡®

---

## å®é™…é›†æˆä»£ç æ¨¡æ¿

### æ¨¡æ¿ 1: åŸºç¡€é›†æˆ

```python
#!/usr/bin/env python3
"""
Workflow command with DocLoader integration
"""

from commands.lib.doc_loader import DocLoader

def load_documentation(mode: str, task_type: str = None):
    """
    æ™ºèƒ½åŠ è½½æ–‡æ¡£

    Args:
        mode: å·¥ä½œæ¨¡å¼ (quick/full/task)
        task_type: ä»»åŠ¡ç±»å‹ï¼ˆå¯é€‰ï¼‰

    Returns:
        åŠ è½½çš„æ–‡æ¡£å†…å®¹
    """
    loader = DocLoader()

    if mode == "quick":
        # å¿«é€Ÿæ¨¡å¼ï¼šåªåŠ è½½æ‘˜è¦
        return loader.load_summary("docs/guides/workflow_guide.md")

    elif mode == "full":
        # å®Œæ•´æ¨¡å¼ï¼šåŠ è½½æ‰€æœ‰ç« èŠ‚
        return loader.load_sections(
            "docs/guides/workflow_guide.md",
            sections=["Step 1", "Step 2", "Step 3", "Step 4"]
        )

    elif mode == "task":
        # ä»»åŠ¡æ¨¡å¼ï¼šæ ¹æ®ä»»åŠ¡ç±»å‹åŠ è½½
        task_sections = {
            "implementation": ["Step 3: å¼€å‘", "Step 4: æµ‹è¯•"],
            "debugging": ["Step 5: è°ƒè¯•", "Step 6: ä¿®å¤"],
            "review": ["Step 7: å®¡æŸ¥", "Step 8: ä¼˜åŒ–"]
        }

        sections = task_sections.get(task_type, ["Step 1"])
        return loader.load_sections(
            "docs/guides/workflow_guide.md",
            sections=sections
        )

    # é»˜è®¤ï¼šæ‘˜è¦
    return loader.load_summary("docs/guides/workflow_guide.md")

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    docs = load_documentation(mode="task", task_type="implementation")
    print(f"Loaded {len(docs)} sections")
```

### æ¨¡æ¿ 2: å¸¦ Token é¢„ç®—æ§åˆ¶

```python
from commands.lib.doc_loader import DocLoader

def load_with_budget(doc_path: str, sections: list, max_tokens: int = 2000):
    """
    å¸¦ token é¢„ç®—æ§åˆ¶çš„æ–‡æ¡£åŠ è½½

    Args:
        doc_path: æ–‡æ¡£è·¯å¾„
        sections: éœ€è¦çš„ç« èŠ‚åˆ—è¡¨
        max_tokens: æœ€å¤§ token é™åˆ¶

    Returns:
        åŠ è½½çš„å†…å®¹ï¼ˆå¯èƒ½è¢«æˆªæ–­ï¼‰
    """
    loader = DocLoader()

    # å…ˆå°è¯•åŠ è½½æ‰€æœ‰ç« èŠ‚
    content = loader.load_sections(doc_path, sections)

    # ä¼°ç®— token
    full_content = "\n\n".join(content.values())
    estimated = loader.estimate_tokens(full_content)

    if estimated > max_tokens:
        print(f"âš ï¸ å†…å®¹è¿‡å¤§ ({estimated} tokens)ï¼Œä½¿ç”¨æ‘˜è¦æ¨¡å¼")
        return loader.load_summary(doc_path)
    else:
        print(f"âœ… å†…å®¹é€‚ä¸­ ({estimated} tokens)ï¼ŒåŠ è½½å®Œæˆ")
        return content

# ä½¿ç”¨ç¤ºä¾‹
content = load_with_budget(
    "docs/guides/workflow_guide.md",
    sections=["Step 1", "Step 2", "Step 3"],
    max_tokens=2000
)
```

---

## æ€§èƒ½ç›‘æ§

### Token æ¶ˆè€—å¯¹æ¯”

é›†æˆå‰åçš„å®é™…æ•°æ®æ”¶é›†ï¼š

```python
from commands.lib.doc_loader import DocLoader

def measure_optimization():
    """æµ‹é‡ä¼˜åŒ–æ•ˆæœ"""

    # Before: å…¨æ–‡åŠ è½½
    with open("docs/guides/workflow_guide.md", 'r') as f:
        full_content = f.read()

    before_tokens = len(full_content) // 4

    # After: ç« èŠ‚åŠ è½½
    loader = DocLoader()
    sections = loader.load_sections(
        "docs/guides/workflow_guide.md",
        sections=["Step 3", "Step 5"]
    )

    after_content = "\n".join(sections.values())
    after_tokens = loader.estimate_tokens(after_content)

    # è®¡ç®—ä¼˜åŒ–
    reduction = (before_tokens - after_tokens) / before_tokens * 100

    print(f"ğŸ“Š ä¼˜åŒ–æ•ˆæœ:")
    print(f"   Before: {before_tokens} tokens")
    print(f"   After:  {after_tokens} tokens")
    print(f"   Reduction: {reduction:.1f}%")

    return {
        "before": before_tokens,
        "after": after_tokens,
        "reduction_pct": reduction
    }
```

---

## æ•…éšœæ’æŸ¥

### å¸¸è§é—®é¢˜

1. **ç« èŠ‚æœªæ‰¾åˆ°**
   - æ£€æŸ¥ç« èŠ‚æ ‡é¢˜æ˜¯å¦å®Œå…¨åŒ¹é…
   - ä½¿ç”¨ Grep å·¥å…·æŸ¥æ‰¾å®é™…æ ‡é¢˜
   - éªŒè¯æ–‡æ¡£ç»“æ„

2. **Token ä¼°ç®—ä¸å‡†**
   - å½“å‰å…¬å¼: `len(content) // 4`
   - é€‚ç”¨äºä¸­è‹±æ··åˆæ–‡æ¡£
   - çº¯ä»£ç æ–‡æ¡£å¯èƒ½åä½ 10-20%

3. **ç¼“å­˜æœªå‘½ä¸­**
   - æ£€æŸ¥è·¯å¾„æ˜¯å¦ä¸€è‡´
   - éªŒè¯ use_cache å‚æ•°
   - è€ƒè™‘æ¸…ç†è¿‡æœŸç¼“å­˜

---

## ç›¸å…³æ–‡æ¡£

- [DocLoader ä½¿ç”¨æŒ‡å—](doc_loader_usage.md)
- [DocLoader æºä»£ç ](../../commands/lib/doc_loader.py)
- [ADR: ä¸‰å±‚æ¶æ„è¿ç§»](../adr/2025-12-09-workflow-three-tier-architecture.md)

---

**åˆ›å»ºæ—¥æœŸ**: 2025-12-09
**æœ€åæ›´æ–°**: 2025-12-09
**ç»´æŠ¤è€…**: AI Workflow Team
